{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import glob\n",
    "import zipfile\n",
    "import rasterio\n",
    "import os\n",
    "import xarray as xr\n",
    "import json\n",
    "from rasterstats import zonal_stats\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "print(os.getcwd())\n",
    "from pathlib import Path\n",
    "folder = Path(r'../Data') # assumes working directory is onhm-fetcher-parser\n",
    "print(folder)\n",
    "shapefiles = folder.glob(\"*_0[1].shp\")\n",
    "# shapefiles = folder.glob(\"*.shp\")\n",
    "gdf = pd.concat([\n",
    "    gpd.read_file(shp)\n",
    "    for shp in shapefiles\n",
    "]).pipe(gpd.GeoDataFrame)\n",
    "gdf.reset_index(drop=True, inplace=True)\n",
    "# gdf.plot()\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "var=lat&var=lon&var=tmax&north=54&west=-126&east=-65&south=23&disableProjSubset=on&horizStride=1&time_start=2018-12-31T00%3A00%3A00Z&time_end=2018-12-31T00%3A00%3A00Z&timeStride=1&accept=netcdf\n",
      "Gridmet data retrieved!\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "<function BufferedWriter.close>"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 2
    }
   ],
   "source": [
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import urlencode\n",
    "\n",
    "prcpurl = 'https://thredds.daac.ornl.gov/thredds/ncss/ornldaac/1328/2018/daymet_v3_tmax_2018_na.nc4'\n",
    "prcppayload = {\n",
    "    'var': 'lat&var=lon&var=tmax',\n",
    "    'north': '54',\n",
    "    'west': '-126',\n",
    "    'east': '-65',\n",
    "    'south': '23',\n",
    "    'disableProjSubset': 'on',\n",
    "    'horizStride': '1',\n",
    "    'time_start': '2018-12-31T00:00:00Z',\n",
    "    'time_end': '2018-12-31T00:00:00Z',\n",
    "    'timeStride': '1',\n",
    "    'accept': 'netcdf'}    \n",
    "try:\n",
    "    s = requests.Session()\n",
    "    #https://github.com/psf/requests/issues/1454\n",
    "    qry = urlencode(prcppayload).replace('%26','&')\n",
    "    qry = qry.replace('%3D', '=')\n",
    "    print(qry)\n",
    "    tmaxfile = requests.get(prcpurl, params=qry)\n",
    "    tmaxfile.raise_for_status()\n",
    "except HTTPError as http_err:\n",
    "    print(f'HTTP error occured: {http_err}')\n",
    "except Exception as err:\n",
    "    print(f'Other error occured: {err}')\n",
    "else:\n",
    "    print('Gridmet data retrieved!')\n",
    "    \n",
    "with open('tmax_test2.nc', 'wb') as fh:\n",
    "    fh.write(tmaxfile.content)\n",
    "fh.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "tmax_test2.nc\n<xarray.Dataset>\nDimensions:                  (time: 1, x: 5904, y: 3377)\nCoordinates:\n  * y                        (y) float32 1687.0 1686.0 ... -1688.0 -1689.0\n  * x                        (x) float32 -2650.25 -2649.25 ... 3251.75 3252.75\n  * time                     (time) datetime64[ns] 2018-12-30T12:00:00\nData variables:\n    lat                      (y, x) float32 ...\n    lambert_conformal_conic  int16 ...\n    lon                      (y, x) float32 ...\n    tmax                     (time, y, x) float32 ...\nAttributes:\n    _NCProperties:       version=1|netcdflibversion=4.6.1|hdf5libversion=1.10.2\n    start_year:          2018\n    source:              Daymet Software Version 3.0\n    Version_software:    Daymet Software Version 3.0\n    Version_data:        Daymet Data Version 3.0\n    Conventions:         CF-1.6\n    citation:            Please see http://daymet.ornl.gov/ for current Dayme...\n    references:          Please see http://daymet.ornl.gov/ for current infor...\n    History:             Translated to CF-1.0 Conventions by Netcdf-Java CDM ...\n    geospatial_lat_min:  21.185654454541883\n    geospatial_lat_max:  58.14529038788518\n    geospatial_lon_min:  -141.7181355648655\n    geospatial_lon_max:  -50.72062839852924\n\n The meta data is: \n {'_NCProperties': 'version=1|netcdflibversion=4.6.1|hdf5libversion=1.10.2', 'start_year': 2018, 'source': 'Daymet Software Version 3.0', 'Version_software': 'Daymet Software Version 3.0', 'Version_data': 'Daymet Data Version 3.0', 'Conventions': 'CF-1.6', 'citation': 'Please see http://daymet.ornl.gov/ for current Daymet data citation information', 'references': 'Please see http://daymet.ornl.gov/ for current information on Daymet references', 'History': 'Translated to CF-1.0 Conventions by Netcdf-Java CDM (CFGridWriter2)\\nOriginal Dataset = /daymet/V3/CFMosaic/2018/daymet_v3_tmax_2018_na.nc4; Translation Date = 2020-01-28T22:25:55.953Z', 'geospatial_lat_min': 21.185654454541883, 'geospatial_lat_max': 58.14529038788518, 'geospatial_lon_min': -141.7181355648655, 'geospatial_lon_max': -50.72062839852924}\n\n The crs meta data is \n {'grid_mapping_name': 'lambert_conformal_conic', 'longitude_of_central_meridian': -100.0, 'latitude_of_projection_origin': 42.5, 'false_easting': 0.0, 'false_northing': 0.0, 'standard_parallel': array([25., 60.]), 'semi_major_axis': 6378137.0, 'inverse_flattening': 298.257223563, '_CoordinateTransformType': 'Projection', '_CoordinateAxisTypes': 'GeoX GeoY'}\n<xarray.DataArray 'tmax' (time: 1, y: 3377, x: 5904)>\n[19937808 values with dtype=float32]\nCoordinates:\n  * y        (y) float32 1687.0 1686.0 1685.0 1684.0 ... -1687.0 -1688.0 -1689.0\n  * x        (x) float32 -2650.25 -2649.25 -2648.25 ... 3250.75 3251.75 3252.75\n  * time     (time) datetime64[ns] 2018-12-30T12:00:00\nAttributes:\n    long_name:     daily maximum temperature\n    units:         degrees C\n    grid_mapping:  lambert_conformal_conic\n    cell_methods:  area: mean time: maximum\n    _ChunkSizes:   [   1 1000 1000]\n\n Data attributes, sizes, and coords \n\n\n Data attributes are: \n {'long_name': 'daily maximum temperature', 'units': 'degrees C', 'grid_mapping': 'lambert_conformal_conic', 'cell_methods': 'area: mean time: maximum', '_ChunkSizes': array([   1, 1000, 1000])}\n\n Data sizes are: \n Frozen({'time': 1, 'y': 3377, 'x': 5904})\n\n Data coords are: \n Coordinates:\n  * y        (y) float32 1687.0 1686.0 1685.0 1684.0 ... -1687.0 -1688.0 -1689.0\n  * x        (x) float32 -2650.25 -2649.25 -2648.25 ... 3250.75 3251.75 3252.75\n  * time     (time) datetime64[ns] 2018-12-30T12:00:00\n\n Lat coords are: \n {'units': 'degrees_north', 'long_name': 'latitude coordinate', 'standard_name': 'latitude', '_ChunkSizes': array([1010,  977]), '_CoordinateAxisType': 'Lat', 'grid_mapping': 'lambert_conformal_conic'}\nxarray.core.utils.Frozen\n1\n1 5904 3377\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "\n",
    "dirPath = 'tmax_test2.nc'\n",
    "\n",
    "#--------------------------------------------------------\n",
    "#   FORM FILENAME AND GET HANDLE TO FILE AND DATA\n",
    "#--------------------------------------------------------\n",
    "fullfilename= dirPath\n",
    "print(fullfilename)\n",
    "\n",
    "ds = xr.open_dataset(fullfilename)\n",
    "\n",
    "print(ds)\n",
    "\n",
    "# df = ds.to_dataframe()\n",
    "\n",
    "print('\\n The meta data is: \\n', ds.attrs)\n",
    "lathandle=ds['lat']\n",
    "lonhandle=ds['lon']\n",
    "timehandle=ds['time']\n",
    "datahandle=ds['tmax']\n",
    "dhlat = ds['lat']\n",
    "dhlon = ds['lon']\n",
    "crshandle=ds['lambert_conformal_conic']\n",
    "print('\\n The crs meta data is \\n', crshandle.attrs)\n",
    "print(datahandle)\n",
    "# crstransform = crshandle.attrs['GeoTransform']\n",
    "# print(crstransform)\n",
    "\n",
    "#collect data to describe geotransform\n",
    "lonmin = float(ds.attrs['geospatial_lon_min'])\n",
    "latmax = float(ds.attrs['geospatial_lat_max'])\n",
    "# lonres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "# latres = float(ds.attrs['geospatial_lon_resolution'])\n",
    "\n",
    "#Print some information on the data\n",
    "\n",
    "print('\\n Data attributes, sizes, and coords \\n') \n",
    "print('\\n Data attributes are: \\n',datahandle.attrs)\n",
    "print('\\n Data sizes are: \\n', datahandle.sizes)\n",
    "print('\\n Data coords are: \\n', datahandle.coords)\n",
    "print('\\n Lat coords are: \\n', dhlat.attrs)\n",
    "\n",
    "ts = datahandle.sizes\n",
    "print(type(ts))\n",
    "print(ts['time'])\n",
    "dayshape = ts['time']\n",
    "Lonshape = ts['x']\n",
    "Latshape = ts['y']\n",
    "#dayshape,lonshape,latshape = datahandle.values.shape\n",
    "print(dayshape, Lonshape, Latshape)\n",
    "\n",
    "# datahandle.values[dayshape-1,:,:].shape\n",
    "\n",
    "# print(lathandle.values.shape)\n",
    "# print(type(lathandle.values))\n",
    "# print(datahandle.dtype)\n",
    "# print(np.isfortran(datahandle.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-4-e4b0019bc98e>\"\u001b[1;36m, line \u001b[1;32m19\u001b[0m\n\u001b[1;33m    3 = wght_dm.groupby('hru_id_nat')\u001b[0m\n\u001b[1;37m                                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m can't assign to literal\n"
     ],
     "ename": "SyntaxError",
     "evalue": "can't assign to literal (<ipython-input-4-e4b0019bc98e>, line 19)",
     "output_type": "error"
    }
   ],
   "source": [
    "# add tmax column to dataframe\n",
    "gdf['tmax']=0.0\n",
    "\n",
    "#open weight data\n",
    "# wght_df = pd.read_csv('../Data/hru_metdata_weights.csv')\n",
    "# wght_df_40 = pd.read_csv('../Data/hru_metdata_weights_40m.csv')\n",
    "# wght_df_500 = pd.read_csv('../Data/hru_metdata_weights_500m.csv')\n",
    "# wght_UofI = pd.read_csv('../Data/hru_uofimetdata_weights.csv')\n",
    "wght_dm = pd.read_csv('../pkg/tmp_weights.csv')\n",
    "# print(len(wght_df['hru_id_nat'].unique()), len(wght_df_40['hru_id_nat'].unique()), \n",
    "#       len(wght_df_500['hru_id_nat'].unique()), len(wght_UofI['hru_id_nat'].unique()))\n",
    "print(wght_dm.head())\n",
    "\n",
    "#iterate through hru's, grab all weights associated with hru_id, get total weighted value from netcdf file, assign to tmax\n",
    "ndata = datahandle.values[dayshape-1,:,:].flatten(order='K')\n",
    "# ndata=np.nan_to_num(data)\n",
    "print(ndata[1000:])\n",
    "# def w_mean(data)\n",
    "3 = wght_dm.groupby('hru_id_nat')\n",
    "print(len(gdf), len(unique_hru_ids))\n",
    "\n",
    "def get_wval(grp, ndata):\n",
    "    ttmax = twght = 0.0\n",
    "    for index, row in grp.iterrows():\n",
    "        ttmax += row['w']*ndata[np.int(row['grid_ids'])]\n",
    "        twght += row['w']\n",
    "    return ttmax/twght\n",
    "def np_get_wval(grp, ndata):\n",
    "    return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "def np_get_wval2(grp, ndata):\n",
    "    mdata = np.ma.masked_array(ndata[grp['grid_ids'].values.astype(int)], np.isnan(ndata[grp['grid_ids'].values.astype(int)]))\n",
    "    return np.ma.average(mdata, weights=grp['w'])\n",
    "#     return np.average(ndata[grp['grid_ids'].values.astype(int)], weights=grp['w'])\n",
    "    \n",
    "# unique_hru_ids.get_group(gdf['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})    \n",
    "td = np.zeros(len(gdf.index))\n",
    "for index, row in gdf.iterrows():\n",
    "    weight_id_rows = unique_hru_ids.get_group(row['hru_id_nat'])\n",
    "#     print(weight_id_rows['grid_ids'].values.astype(int))\n",
    "#     unique_hru_ids.get_group(row['hru_id_nat']).agg({'tmax': np_get_wval(weight_id_rows, ndata)})\n",
    "#     gdf.loc[gdf.index[index],'tmax'] = np_get_wval(weight_id_rows, ndata)-273.5\n",
    "    tmp = np_get_wval2(weight_id_rows, ndata)\n",
    "    if index == 1:\n",
    "        print(type(tmp))\n",
    "    td[index] = np_get_wval2(weight_id_rows, ndata)\n",
    "#     if td[index] < 0.0:\n",
    "#         print(ndata[weight_id_rows['grid_ids'].values.astype(int)], weight_id_rows['w'])\n",
    "#     print(index, td[index])\n",
    "#     if row['hru_id_nat'] == 829:\n",
    "#         print(\"in test\")\n",
    "#         for i2, el in weight_id_rows.iterrows():\n",
    "#             print(el['w'], ndata[el['grid_ids'].astype(int)])\n",
    "#         print(np.average(ndata[weight_id_rows['grid_ids'].values.astype(int)], weights=weight_id_rows['w'])-273.5)\n",
    "#     print(index, row['hru_id_nat'], np_get_wval(weight_id_rows, ndata)-273.5)\n",
    "#     gdf.loc[gdf.index[index], 'tmax'] =\n",
    "# #     print(get_wval(weight_id_rows, ndata)-273.5)\n",
    "# #     row.loc['tmax']=get_wval(weight_id_rows, ndata)-273.5\n",
    "# #     gdf.loc[gdf.index[index], 'tmax'] = get_wval(weight_id_rows, ndata)-273.5\n",
    "# print(len(td))\n",
    "# gdf['tmax'] = gpd.GeoSeries([np.transpose(td)], index=gdf.index)\n",
    "gdf['tmax'] = td.tolist()\n",
    "gdf['tmax'].fillna(0.0)\n",
    "# print(td.tolist())\n",
    "print('min/max', gdf['tmax'].min(), gdf['tmax'].max())\n",
    "# print(gdf)\n",
    "# gdf.plot(figsize=(12,12), column = 'tmax',linewidth=0.25, edgecolor='white')    \n",
    "# print(gdf.groupby(tmax).min)\n",
    "# f, ax = plt.subplots(2, figsize=(12,12))\n",
    "# gdf.plot(ax=ax[0], column = 'tmax',linewidth=0., edgecolor='white', scheme='quantiles')\n",
    "# ptmax = ds.air_temperature-273.5\n",
    "# ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "# lvs = np.arange(gdf['tmax'].min(), gdf['tmax'].max(), 0.5)\n",
    "# ptmax_1.plot(ax=ax[1], levels=lvs, cmap='viridis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "f, ax = plt.subplots(1)\n",
    "ax.set_aspect('equal')\n",
    "# ax.axis('equal')\n",
    "# ax1.set(xlim=(-130, -60), ylim=(20, 55))\n",
    "# divider_0 = make_axes_locatable(ax[0])\n",
    "# cax_0 = divider_0.append_axes(\"right\", size=\"5%\", pad=0.1)\n",
    "lvs = np.arange(gdf['tmax'].min(), gdf['tmax'].max(), 0.1)\n",
    "gdf.plot(ax=ax, column = 'tmax',linewidth=0., edgecolor='white', k=20)\n",
    "f.savefig('hru.png')\n",
    "f.tight_layout()\n",
    "# f1, ax1 = plt.subplots(1)\n",
    "# ax1.set_aspect('equal')\n",
    "# # ax1.set(xlim=(-130, -60), ylim=(20, 55))\n",
    "# ptmax = ds.air_temperature-273.5\n",
    "# ptmax_1 = ptmax.isel(day=dayshape-1)\n",
    "# ptmax_1.plot(ax=ax1, levels=lvs, cmap='viridis')\n",
    "# f1.tight_layout()\n",
    "# f1.savefig('gridmet.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "gdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}